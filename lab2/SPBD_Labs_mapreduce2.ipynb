{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smduarte/spbd-2223/blob/main/lab2/SPBD_Labs_mapreduce2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKGXsDUIDxH6"
      },
      "source": [
        "# MrJob MapReduce Python Example\n",
        "\n",
        "Word count implemented in pure Python, using the library MrJob.\n",
        "\n",
        "[MrJob](https://mrjob.readthedocs.io/en/latest/) can be used to write MapReduce jobs and run them on several platforms.\n",
        "\n",
        "Some key advantages:\n",
        "+ Write **multi-step** MapReduce jobs in pure Python;\n",
        "+ Test on your **local machine**;\n",
        "+ Deploy jobs in several cloud plataforms of several vendors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "scrolled": false,
        "id": "B68ZyGdPDxH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9a11cf-fe70-403e-e243-45d7ea8cb83c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 2.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 1.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51 kB 1.8 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71 kB 2.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 92 kB 2.7 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 112 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 133 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 143 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 153 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 174 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 184 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 194 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 215 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 225 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 235 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 245 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 256 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 266 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 276 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 286 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 296 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 307 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 317 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 327 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 337 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 348 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 358 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 368 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 378 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 389 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 399 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 409 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 419 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 430 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 439 kB 2.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title Download the dataset and install MrJob\n",
        "!wget -q -O os_maias.txt https://www.dropbox.com/s/n24v0z7y79np319/os_maias.txt?dl=0\n",
        "!pip install mrjob --quiet\n",
        "!wget -q -O /etc/mrjob.conf https://raw.githubusercontent.com/smduarte/spbd-2223/main/lab2/mrjob.conf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8sllMoIDxH_"
      },
      "source": [
        "### MrJob WordCount Example\n",
        "Read the words from input and count them.\n",
        "\n",
        "The processing is split into two main phases:\n",
        "\n",
        "+ The mapper emits for each line the number of words\n",
        "+ The reduces sums all the tuples produced by the mapper stage...\n",
        "\n",
        "Using MrJob, a MapReduce job can be expressed in a single Python class,\n",
        "with methods for each of the phases. The reducer phase is called separately for each key, with the collection of values to be reduced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LbItx5zwDxIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c907b64-8699-4381-e5cb-1ce63393822a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing wordcount.py\n"
          ]
        }
      ],
      "source": [
        "%%file wordcount.py\n",
        "\n",
        "import string  \n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class MRWordCount(MRJob):\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "      # remove leading and trailing whitespace\n",
        "      line = line.strip()\n",
        "      # remove punctuation characters\n",
        "      line = line.translate(str.maketrans('', '', string.punctuation+'«»'))\n",
        "      # split the line into words\n",
        "      yield \"words\", len(line.split())\n",
        "\n",
        "    def reducer(self, key, values):\n",
        "        yield key, sum(values)\n",
        "            \n",
        "if __name__ == '__main__':\n",
        "    MRWordCount.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stOA47uRDxIC"
      },
      "source": [
        "## Execution of MrJob programs\n",
        "\n",
        "### Local Execution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wordcount\n",
        "\n",
        "# prepare the mapreduce job for local execution\n",
        "mr_job = wordcount.MRWordCount(args=['-r', 'local','os_maias.txt'])\n",
        "\n",
        "# execute the job and print the output results\n",
        "with mr_job.make_runner() as runner:\n",
        "    runner.run()\n",
        "    for key, value in mr_job.parse_output(runner.cat_output()):\n",
        "        print( key, value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6EFN43316on",
        "outputId": "baa0b9ab-98f8-449c-9e82-94855ee5a277"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words 213359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supplying a combiner...\n"
      ],
      "metadata": {
        "id": "6IpXfJ-iE-1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file wordcount2.py\n",
        "\n",
        "import string  \n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class MRWordCount(MRJob):\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "      # remove leading and trailing whitespace\n",
        "      line = line.strip()\n",
        "      # remove punctuation characters\n",
        "      line = line.translate(str.maketrans('', '', string.punctuation+'«»'))\n",
        "      # split the line into words\n",
        "      yield \"words\", len(line.split())\n",
        "\n",
        "    def combiner(self, key, values):\n",
        "        yield key, sum(values)\n",
        "\n",
        "    def reducer(self, key, values):\n",
        "        yield key, sum(values)\n",
        "            \n",
        "if __name__ == '__main__':\n",
        "    MRWordCount.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjYU2QVuFLlJ",
        "outputId": "df7619bd-3df8-43da-8958-0291017c0142"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing wordcount2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wordcount2\n",
        "\n",
        "# prepare the mapreduce job for local execution\n",
        "mr_job = wordcount2.MRWordCount(args=['-r', 'local','os_maias.txt'])\n",
        "\n",
        "# execute the job and print the output results\n",
        "with mr_job.make_runner() as runner:\n",
        "    runner.run()\n",
        "    for key, value in mr_job.parse_output(runner.cat_output()):\n",
        "        print( key, value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaVofcsCFSx0",
        "outputId": "378c4958-75b5-45c0-9f9e-fb9f418c3b26"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words 213359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MrJob Hadoop Execution\n",
        "\n",
        "The main difference is that the input files and the output results need to be stored in HDFS (Hadoop distributed filesystem)\n",
        "\n",
        "For now, we will use MrJob in local mode."
      ],
      "metadata": {
        "id": "MMu6OTgpKFLS"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}