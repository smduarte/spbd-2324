{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1-I-sX7bhFegTI0od-ithkfVPYhVQ-X42",
      "authorship_tag": "ABX9TyM6xtKEDx0qhfBGLB1wE9fc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smduarte/spbd-2324/blob/main/proj/SPBD2324_Proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPBD-2324 Project Assignment\n",
        "\n",
        "#### version 1.0 - 15/11 (Final)\n",
        "\n",
        "The project scenario involves a dataset of taxi rides, collected December 2022, in the New York city area.\n",
        "\n",
        "Each completed taxi ride corresponds to an event in the dataset. A ride comprises several items of information, including the pick-up and drop-off zones/regions within NY City, their respective timestamps, as well as information related to the payment and number of passengers reported by the driver. The full explanation of the available data is provided [here](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf).\n",
        "\n",
        "A table to convert zone identifiers into proper names is found [here](https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv).\n",
        "\n",
        "The project assignment will comprise a set of queries. All must be solved using Spark SQL Dataframes API. One query **of your choice** needs to be solved twice more, using Spark Core (mandatory) and, either using the SQL flavor of SparkSQL or using MrJOB.\n",
        "\n",
        "# Queries\n",
        "\n",
        "## Q1 - Basic Statistics\n",
        "\n",
        "Compute for each day of the week, the total number of rides, the average ride duration, cost and distance travelled.\n",
        "\n",
        "## Q2 Top-5 New York **boroughs**\n",
        "\n",
        "Compute the top-5 New York **boroughs** most popular for pick-ups and dropoffs, for the whole month and for each day of the week, separately.\n",
        "\n",
        "## Q3 - Compute a list of anomalous rides.\n",
        "\n",
        "Anomalous rides are those that deviate, significantly, either in terms of cost or distance travelled, from rides that started and ended in the same zone.\n",
        "\n",
        "## Q4 - Find the which zones tend to generate shorter rides and which generate longer rides.\n",
        "\n",
        " Consider a ride short or long, respectively, if it less or more than 30% than the average distance for rides that originate in that zone.\n",
        "\n",
        "## Q5 - Find most important city zones using the Pagerank metric.\n",
        "\n",
        "  Consider the graph where locations/zones (vertices) are connected by the\n",
        "  taxi rides (edges). Locations that have many incoming rides, ie., those that are the dropoff location for many rides, will tend to be important hubs (centers of activity) in the city. Use Pagerank to find these hubs.\n",
        "  \n",
        "  To that end, to simplify the graph, do not consider rides that involve \"Unknown\" zones. Additionally, for each zone, only consider the rides that start in that zone and end in the top-5 destinations for that zone (This will remove the edges corresponding to (src-dst) zone pairs that are not very popular).\n",
        "\n",
        "  Use the [GraphFrames API](https://graphframes.github.io/graphframes/docs/_site/index.html) and check the example below for a simple PageRank computation.\n",
        "\n",
        "# Deadline\n",
        " + 8th December - 23h59\n",
        " + For each day late, a penalty of 0.5/20 grade points applies."
      ],
      "metadata": {
        "id": "IRibc6b3mULe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Code\n",
        "\n",
        "The cells below show how to download the dataset and\n",
        "start processing it using Spark Core and SparkSQL."
      ],
      "metadata": {
        "id": "75rHfXd64EbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Dataset\n",
        "!wget -q -O taxirides.csv.gz https://shorturl.at/mzHKY\n",
        "!gzip -cd taxirides.csv.gz | head -1000 > taxirides.csv"
      ],
      "metadata": {
        "id": "b7vlO1ERgAkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install PySpark\n",
        "!pip install --quiet pyspark"
      ],
      "metadata": {
        "id": "Wm12pEqlZc9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Spark Core Example\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]').appName('NYCtaxis').getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "try :\n",
        "  rides = sc.textFile('taxirides.csv.gz')\n",
        "\n",
        "  for ride in rides.take(10):\n",
        "    print(ride)\n",
        "\n",
        "  sc.stop()\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  sc.stop()"
      ],
      "metadata": {
        "id": "tJDZB0KxZK9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SparkSQL Example\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]').appName('NYCtaxis').getOrCreate()\n",
        "\n",
        "try :\n",
        "  trips = spark.read.csv(path = \"taxirides.csv\", header= True, inferSchema= True )\n",
        "  trips.printSchema()\n",
        "  trips.show(5)\n",
        "\n",
        "except Exception as err:\n",
        "  print(err)"
      ],
      "metadata": {
        "id": "qz0zswfyZara"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Q4 Graphframes\n",
        "\n",
        "!pip install --quiet graphframes\n",
        "\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from graphframes import *\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "try:\n",
        "\n",
        "  spark = SparkSession.builder.master('local[*]') \\\n",
        "          .config('spark.jars.packages', 'graphframes:graphframes:0.8.3-spark3.5-s_2.12')\\\n",
        "          .appName('Graphframes example').getOrCreate()\n",
        "\n",
        "\n",
        "  # Create a Vertex DataFrame with unique ID column \"id\"\n",
        "  v = spark.createDataFrame([\n",
        "  (\"a\", \"Alice\", 34),\n",
        "  (\"b\", \"Bob\", 36),\n",
        "  (\"c\", \"Charlie\", 30),\n",
        "  ], [\"id\", \"name\", \"age\"])\n",
        "\n",
        "\n",
        "  # Create an Edge DataFrame with \"src\" and \"dst\" columns\n",
        "  e = spark.createDataFrame([\n",
        "  (\"a\", \"b\", \"friend\"),\n",
        "  (\"b\", \"c\", \"follow\"),\n",
        "  (\"c\", \"b\", \"follow\"),\n",
        "  ], [\"src\", \"dst\", \"relationship\"])\n",
        "\n",
        "  # Create a GraphFramefrom graphframes import *\n",
        "  g = GraphFrame(v, e)\n",
        "\n",
        "  # Query: Get in-degree of each vertex.\n",
        "  g.inDegrees.show()\n",
        "\n",
        "  # Query: Count the number of \"follow\" connections in the graph.\n",
        "  g.edges.filter(\"relationship = 'follow'\").count()\n",
        "\n",
        "  # Run PageRank algorithm, and show results.\n",
        "  results = g.pageRank(resetProbability=0.01, maxIter=20)\n",
        "  results.vertices.select(\"id\", \"pagerank\").show()\n",
        "\n",
        "except Exception as err:\n",
        "  print(err)\n"
      ],
      "metadata": {
        "id": "1AziOLNYTRUo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}